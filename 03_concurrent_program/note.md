## 进程介绍

1. 计算机cpu的时间片：在同一时刻cpu只能运行一个进程，哪个进程占有cpu，就称那个进程在cpu的时间片上
2. 多任务编程：同时可以利用cpu的多核资源，运行多个任务。多进程和多线程都是多任务编程的具体方法
3. 从程序的运行本质上，程序分为IO密集型和cpu密集型程序
```
IO：input、output, 在内存中存在数据交换的部分都叫IO操作如：input、print，文件读写，数据库的存取，  网络的数据传输）
运算：运算需要使用到cpu，语句的逻辑分析、计算、数学运算、内存运算

IO密集型程序：IO操作远远大于运算操作，因为cpu效能相对磁盘读写好的多，所以这类程序一般cpu大多状态是在等待IO, 所以运算cpu占用很低（影响程序运行流畅度的关键是硬盘）
CPU密集型：程序中运算较多，IO较少，大多数情况下cpu占用比较高
```
4. 进程：程序的一次执行过程
```
程序是指一个文件（磁盘中可执行的代码，是静态的）, 进程是程序被读取到内存中，被操作系统调用时候开始生命周期，执行结束即结束生命周期，是一个过程，进程是占有cpu和内存的
```
5. 守护进程：系统中的后台服务进程。
```
特点：独立于终端并周期性的执行某种任务，生命周期长，一般随系统启动，随系统终止
```
6. 进程缺点：进程的创建需要消耗较多的系统资源

7. 进程的执行过程（重点）process
```
操作系统内核(kernal) ---> 决定了进程的创建
linux下创建进程会在内存中自动生成一个PCB（进程控制块）
    PCB：内存中的一小块空间，功能用来记录进程的各种信息，包括pid，name调度信息，优先级，状态，虚拟地址空间等
    PID：操作系统中每个进程都有一个唯一的ID号，叫做该进程的PID，PID号由系统分派
虚拟地址(虚拟内存)：是计算机系统内存管理的一种技术，每个进程都占有4个G的虚拟内存，物理内存映射出来的虚拟内存空间，是为了每个进程有足够的内存地址可用，
```


## 进程状态

1. 三态
```
         失去时间片           IO
  就绪 <==========> 执行 ---------> 等待
   ^      调度
   |                               |
   |                               |
   ---------------------------------
                等待完毕
就绪态：进程具备运行条件，等待系统分配处理器以便运行
运行态：进程占有cpu正在运行
等待态：又称阻塞态或者睡眠态，指进程不具备运行条件，正在等待某事件的完成
```


2. 五态：在三态基础上增加新建和终止
```
新建：创建一个进程的过程，直接表现为执行某程序，或者程序中进行子进程的创建
                           终止
                            ^
                            |
                            |
                失去时间片           IO
新建 ---> 就绪 <==========> 执行 ---------> 等待
           ^      调度
           |                               |
           |                               |
           ---------------------------------
                        等待完毕
终止：程序执行结束，完成善后（善后不好容易产生僵尸）
```


## ps命令列出进程信息

1. ps -aux 显示系统中进程的详细信息 （unix不加-：ps aux）
```
stat(状态)
D：等待态(不可中断)   R：运行态   S：等待态(可中断)   T：停止态(暂停执行)  Z：僵尸  <:高优先级的进程   N:低优先级    +：前台运行    s：会话组组长
```
2. ps -ef | grep *  查看某一进程的信息
3. pstree 查看进程树
```
父子进程概念：在系统中每一个进程（除了起始进程）都是由进程创建的，每一个基础有唯一的父进程，可能有多个子进程。子进程继承了父进程大部分属性
```

4. top 动态显示进程信息（linux）
```
使用 shift + < > 换页
NI 优先级： -20 ----- 19 数字越小优先级越高
```

5. nice / renice
```
以指定的优先级运行程序
如： nice -10 ./while.py   以10优先级运行
    sudo nice --10 ./while.py   优先级小于0时

改变已运行的程序的优先级 renice n pid
如：renice 10 4339

运行程序加 & 可以变为后台运行 返回pid号
```


## 使用fork创建进程（适用于Linux 和 unix）

1. 导入os 模块（标准块模块）和操作系统相关, 使用os.fork() 创建进程
```
fork()
    功能：为当前进程创建一个子进程
    参数：无
    返回值：是一个整数，有如下几种情况：
        1、如果返回值为负数，表示进程创建失败
        2、如果返回值等于0，表示这是在子进程中返回的
        3、如果返回值大于0（子进程的pid），表示这是在父进程中返回的
注：
    1、子进程和父进程都是独立存在的，在执行上相互不影响
    2、利用父子进程中fork返回值的不同加以区分，执行内容是固定的方法
    3、父进程中返回值是子进程的pid号
    4、子进程拥有父进程几乎所有的资源，包括fork前已有的变量

os.getpid() 获取当前进程的pid号
os.getppid() 获取当前进程的父进程的pid号
```

2. 进程退出函数：
```
os._exit([status]) 直接退出当前进程
sys.exit([status]) 抛出异常SyetemExit异常，如果异常不被处理则进程结束
参数：表示返回状态，如果不传或者传入0，表示进程正常退出，如果出入一个正整数表示非正常退出，如果传入非数字则打印出来
```

3. 进程处理
```
僵尸处理：进程已经结束，但是在系统中仍然保存着该进程的pcb 信息，会占用一定的内存
产生原因：子进程先于父进程退出，父进程没有进行处理，这时子进程就会成为僵尸进程，僵尸进程是我们不希望的
孤儿进程：父进程先退出，此时子进程就会变为孤儿进程，孤儿进程会被系统专有进程进行收养，并且负责在该孤儿进程退出时“收尸”，所以孤儿进程并没有影响

僵尸进程的处理方法：
    1、父进程使用os.wait 或者 os.waitpid 进行处理
    2、创建二级子进程，让一级子进程退出，则二级子进程成为孤儿
    3、父进程使用信号处理方式处理子进程信号

os.wait() 一般写在父进程最前面
功能：阻塞等待子进程的退出，只要该父进程有任意子进程退出，则结束阻塞
参数：无
返回值：包含两个元素的元组，第一个是退出的子进程的pid，第二个时退出的子进程相关的退出码（调校乘256）, 用 os.WEXITSTATUS(status) 得到没有调校的退出码

os.waitpid(pid, options)
功能：等待子进程退出
参数：pid 传-1     表示任何一个子进程退出都可以
         大于0    表示等待指定的子进程退出
     options  传0     表示始终阻塞等待
             WNOHANG  表示非阻塞等待 （如果等不到子进程退出则返回子进程pid）
返回值：包含两个元素的元组，第一个时退出的子进程的pid，第二个时退出的子进程相关的退出码（调校乘256）
       用 os.WEXITSTATUS(status) 得到没有调校的退出码
wait() == waitpid()
```


## 更方便的管理进程multiprocessing
    步骤：
        1、确定执行事件，将事件封装成函数
        2、使用Process创建新的进程，将要执行的函数传入，得到相应的进程对象
               Process 参数：
               name：起的新的进程名称
               target：传入的目标函数名
               args：以元组的方式向目标函数进行位置传参
               kwargs：以字典的方式向目标函数进行传参
        3、使用相应的对象调用start() 属性函数启动子进程
        4、使用相应对象调用join() 函数等待接受子进程退出
               进程对象p的属性：
               p.pid 相应子进程的pid号
               p.name 子进程的名字
               p.isalive() 子进程的状态
               p.start() 启动子进程
               p.join([timeout]) 回收子进程函数 [timeout]是一个可选参数，表示超时等待时间
               p.daemon 默认为False 表示主进程执行结束后不会立即退出，而是等待子进程结束后再退出。设置为True，
                        那么主进程执行结束后会终止该子进程的执行，并且立即退出。必须在start前设置
               run() start()时自动调用run方法，自定义进程类时常重写之
                    s = 'hi,{}'.format('xiaoming')
                    s = 'hi,{1},{0}'.format('xiaoming', 'xiaohong')


进程池
    多个进程执行任务，任务非常多，且执行时间短，需要频繁创建删除进程时可以利用进程池
    1、使用 pool 创建进程池，得到进程池对象
    2、使用 apply_async 将事件放入进程池等待执行
    3、如果池内有空闲进程则会执行等待的事件
    4、使用 close 关闭进程池，不能够再投放进程
    5、使用 join 阻塞等待进程池内现有所有事件都被执行结束后回收子进程（进程池内所有进程均为子进程）

    进程池对象（pool）的方法：
        pool.apply_async(fun, [args = (), [kwargs = {}]]) 异步加载事件到进程池
        pool.apply(fun, [args = (), [kwargs = {}]]) 同步加载事件到进程池
        pool.close() 关闭进程池
        pool.join() 阻塞，等待进程池子进程退出。必须在close之后
        pool.map() 功能上类似内建函数map 将第二个参数重的每一个数带入到第一个函数中进行传参。
                   然后将该事件放入进程池


进程间通信：不同的进程间进行消息的传递
    文件：不好，文件可以被随意打开、修改。和磁盘的交互也比较慢

    管道：应用在两个进程间通信，以流的方式传递
    1、在内存中开辟的一块空间，对多个进程可见。在形式上有一定的约束
    2、通过 Pipe 创建，返回值有两个分别表示管道的两端
    3、当创建时参数为True(默认)时两个返回值均可以进行send和recv操作，当为False时，第一个只可以recv操作，第二
       个只可send
    4、recv函数为阻塞函数，当管道内为空时会阻塞


消息队列
    1、按照先进先出的原则来存取消息，先放入的消息先被取出
    2、队列中没有消息则为空队列，这时无法执行取消息的操作。队列中消息个数达到上限则为满队，此时无法存入消息
    3、不同进程间，通过向队列存入和获取消息来达到通信的目的
    创建队列：
        from multiprocessing import Queue

        q = Queue(maxsize)
        # 功能：创建消息队列对象
        # 参数：maxsize设置消息队列大小，表示最多存多少个消息

        q.put(obj, block=True, timeout=None)
        # 功能：向队列存入消息
        # 参数：obj要存入的对象  block是否时阻塞模式，默认是True，如果设置为False为非阻塞，队列为满则抛出异常
        #       timeout当block等于True时为阻塞时间，设置时间后超时返回异常

        q.get()
        # 功能：从队列中取出一个消息
        # 参数：block是否时阻塞模式，默认为True表示阻塞，设置为False表示为非阻塞，如果队列为空立即返回empty异常
        #       timeout当block等于True时为阻塞时间，设置时间后超时返回异常

        q.full()
        # 功能：判断队列是否为满，如果满则返回True，否则返回False

        q.empty()
        # 功能：判断队列是否为空，如果空则返回True，否则返回False

        q.qsize()
        # 功能：查看当前对列中消息个数,不过在 Mac OS 上没法运行


共享内存
    特点：1、效率高的进程间通信方式
         2、安全性上有风险，因为内容的存放是会覆盖原有的内容的，所以在使用的时候能有可能已经被篡改
         3、基于2的原因，在使用时经常需要考虑加锁问题
    from multiprocessing import Value, Array
    1、两种方法使用上基本相同，value在共享内存存放一个数值，array可以存放多个数值，但是类型必须相同
    2、任意的进程对共享内存中的数据进行修改后，即其他进程也会获得修改后的数据
    3、两个方法第一个参数相同，都是ctypes，详见表。第二个参数value为一个相应类型的数值，array可以是数值（表示
       开辟一个包含多少数据的内存空间填充0），也可以是一个迭代对象（会给根据内容开辟空间并且将内容进行填充）

                    管道           消息队列           共享内存
       开辟空间      内存             内存              内存
       读写方式      可双向，可单向     先进先出          操作内存
                    消息流           包的个数           数值数组
                    send/recv       put/get          直接修改
       效率          一般             一般             快
       是否需要互斥   不需要           不需要            需要


信号
    是一种异步的通信方式，信号有其名称，含义，和默认行为
    发送信号
    import os
    import signal
    os.kill(pid, signal)
    # 功能：向一个进程发送一个信号
    # 参数：pid向哪个进程发送，该进程的PID号
           signal发送什么信号 使用signal.signum

    signal.alarm(sec)
    # 功能：向自身发送一个信号
    # sec：在sec秒后信号会被发送
    一个进程中只能挂起一个时钟信号

    处理信号
    signal.pause()
    # 功能：挂起等待一个信号

    signal.signal(signal, handler)
    # 功能：处理一个信号
    # 参数：signal：要处理的信号
    #      handler：对信号的处理方法
           处理方法：忽略该信号   SIG_IGN
              使用默认的方法执行   SIG_DFL
              使用指定的方法执行   function
    异步处理：在某一时刻使用signal捕捉信号，会告知内核帮进程监控，而不是阻塞等待。在进程的生命周期内，只要有该信号发送进来就会处理

    僵尸进程处理
    父进程在子进程执行结束前加入
    signal.signal(signal.SIGCHLD, signal.SIG_IGN)


同步和互斥
    临界资源：对多个进程或线程可见，容易产生争夺的资源（如共享内存) 称之为临界资源
    临界区：对临界资源进行操作的代码段，称之为临界区
    同步：同步是一种制约关系，为完成某种任务而建立两个或多个进程，进程间协调而有次序的等待，传递信息，完成工作
         。这种制约源于进程间的合作
    互斥：互斥是一种间接的制约，当一个进程进入临界区进行加锁，其他进程此时无法操作临界资源，只有当该进程结束对
         临界资源的使用后，进行解锁，其他进程才可以使用，这种技术往往是通过阻塞完成的

    同步互斥方法
    from multiprocessing import Event
    e = Event()  创建时间对象
    e.is_set()  判断时间是否被设置
    e.set()   对事件对象进行设置
    e.wait()  阻塞等待事件被设置（参数表示超市时间）

    from multiprocessing import Lock
    lock = Lock()
    lock.acquire()  上锁
    lock.release()  解锁


作业：司机和售票员的故事
    1、创建父子进程分别表示司机和售票员
    2、当售票员捕捉到SIGINT信号时，发送SIGUSR1给司机，司机打印（‘发车了’）
       当售票员捕捉到SIGQUIT信号时，发送SIGUSR2给司机，司机打印（‘到站了， 请下车’）
    3、到站后司机等待售票员先下车，然后自己exit
       温馨提示：当通过键盘发送信号时，会发送给终端的所有进程


线程介绍
    线程也是多任务编程方式之一，可以使用计算机的多核资源
    线程又称轻量级的进程，在并发执行上和进程相同
    但是一个进程中可以包含多个线程，多个线程共享进程的运行环境

    线程的特点：
        1、进程的创建开销较大，而线程的创建开销很小
        2、进程之间资源不能共享，只有通过进程间通信的方式才能传递资源消息，而一个进程包含多个线程，多个线程共享进程的资源，就像多个函数使用全局变量一样
        3、多个功能独立的程序需要成为不同的进程，而不能通过多线程凑成一个进程
        4、进程因为空间独立，数据安全性较高，也较少使用同步互斥方法（只有共享内存等少数技术需要）。而多线程之间因为数据共享，所以同步与互斥几乎时数据传递必须的
        5、线程也有自己独立的资源，比如ID、指令集等


创建线程：thread(python2)  threading
    import threading
    t = threading.Thread(target, args, kwargs, name)
    # 参数功能参照进程Process函数

    t.name: 线程名称
    t.setname(): 设置线程名称
    t.getname(): 获取名称
    t.join(n): 主线程阻塞等待分支线程退出，n为超时时间
    t.start(): 启动线程
    t.Daemon(): daemon属性
    t.setDaemon(): 设置daemon标示位，默认为false，主线程结束会等待分支线程执行结束在退出。如果设置为True，则主线程退出后，所有分支线程同时结束。在start前设置
    t.is_Daemon(): 判断daemon状态
    t.is_alive(): 判断线程状态


线程间通信
    线程间通信方法，通常是使用全局量
    在一个线程中对全局量进行设置或修改，其他线程就可以使用这个量的值，这种方便会带来资源的争夺，所以线程间使用共享资源一般需要同步互斥机制

    线程间同步互斥：
    基本原理和继承一样，当一个线程操作临界资源的时候，其他线程对临界资源无法操作

    方法1：
        lock = threading.Lock()
        lock.acquire() 上锁
        lock.release() 解锁
    方法2:
        e = threading.Event()
        e.set()  设置时间
        e.wait() 阻塞等待事件被设置
        e.clear() 清除设置时间


GIL(全局解释器锁)
    python ---> 支持多线程 ----> 同步和互斥 ----> 加锁 ----> 超级大锁 -----> 解释器在同一时刻只能解释一个线程
    由于库的依赖无法改变现状 -----> python多线程的执行效率极低
    GIL 即 cpython解释器由于上锁带来的同一时刻只能解释一个线程的情况

    解决方法：
        * 使用multiprocessing 替代 Threading
        * 使用其他解释器 只cpython有GIL的问题， 可以使用Jpython和C#解释器等解决这个问题

    效率测试
    单线程：
    Line cpu 85.31724190711975
    line IO 18.134287118911743
    多线程
    line cpu 97.12201309204102
    line IO 25.9390788078308105

    多线程会让IO密集型程序变得更加糟糕，和单进程cpu密集型的程序差不多。对于网络请求较多的程序，多线程的优势还是比较明显的
    多进程无论在CPU密集型还是IO密集型程序中都明显的提高了程序的执行效率


设计模式
    设计模式代表了最佳实践，是被开发人员经过长期开发总结，用来解决某一类常见问题思路方法。通过成熟的设计模式解决问题，保证了代码的效率，可靠性也易于理解
    编程基本原则：高内聚：在同一模块内，实现单一功能，尽量不使功能混杂
                低耦合：不同模块尽量相互独立，减少模块间的影响
    生产者消费者模式


1、IO多路复用 + 多线程
2、异步 + 事件触发模型



看到多线程和多进程，不熟悉的人可能会认为两者是同一个东西，其实两者大有不同。其实看他们原本的英语表达就知道了，多线程是multi threading，而多进程是 multi processing。线程与进程的区别我们在操作系统中已经学习过了，简而言之，进程可以包含多个线程，而线程是进程的一个实体。开线程的代价比开进程的代价小，而且便于通信，但是多进程更稳定一些，毕竟一个线程crash了，整个进程都会挂，而多进程之间通常是独立的。有人看到这可能有疑问，如果我处理好线程安全性的问题，那直接用多线程不就好了。

事情远没有这么简单，由于Python的内存操作并不是线程安全的[1]，Python（此处指大家广泛使用的Python发行版CPython）的设计者对于多线程的操作加了一把锁。这把锁被称为GIL（Global Interpreter Lock）。当然对于不涉及到线程安全的一些操作来说不受影响，主要是那些IO密集型的操作，以及Numpy中的一些运算。也就是说，如果你需要在Python中用并行来加速计算密集型任务的执行的话，那么至少在GIL没有被取消掉的当下，用多线程是走不通的。另外根据官方文档的介绍[1]，会发生一件很有趣的事情，由于系统调度的原因，在多核处理器下执行多线程的计算，会比不使用多线程还要慢。

由于GIL的存在，如果我们需要使用多核来对计算密集型任务进行加速的话，那么我们不能使用多线程，而不得不去使用多进程。但是Python的设计在这里很有迷惑性，他把线程和进程的接口设计的几乎一模一样，除了进程还可以强制终结和一些特有的属性之外，没有任何差别。这给人造成一种错觉，好像是多进程和多线程之间可以无缝替换，当然这可能是设计者的愿景，而其实两者之间的区别是巨大的。前面已经介绍过了，举个具体的例子，比如说数据的流动，在线程中只要指定好就可以了，但是进程间的数据流动一般来说没有那边简单，一般都需要采用一些外部的方式来解决，如Socket，Pipe，共享内存等。另外，由于Unix/Windows可使用的多进程实现方式不同，也导致了多进程的代码具有很强的系统依赖性。

多进程在不同系统下的实现方式
首先先来介绍下Python多进程的实现方式[2]。Unix系统下默认的实现方式是fork，而fork可以将进程复制一份，子进程可以执行与主程序不同的函数，此外，这种方式生成的进程继承了父进程的数据，所以数据可以方便的从父进程流动到子进程。而在Windows上不支持fork，而是要使用spawn。spawn其实也是将进程复制一份，但是进程会重新执行一遍主函数里面的代码，就像父进程一样，然后再去执行相应的函数。所以这就会导致一个问题就是如果我们不加任何判断的话，这个进程会不断的复制自身，形成新的进程。Python的设计者当然考虑到了这一点，所以如果你在spawn进程的初始阶段还尝试创建新进程的话，会报错退出。怎么区别主进程和父进程呢？一般会采用__name__属性来区分。

我们用一段代码来验证一下之前讲的这些结论：

import multiprocessing as mp
import os

# Run phase
def v():
    print('Run', os.getpid())
    print(__name__, os.getpid())

# Initialization phase
print('Initialize', os.getpid())
print(__name__, os.getpid())

if __name__ == '__main__':
    # start a new Process to execute function `v` and wait for it
    p = mp.Process(target=v)
    p.start()
    p.join()
代码在Windows下的输出结果为 （Python 2.7）

('Initialize', 6896)
('__main__', 6896)
('Initialize', 14284)
('__parents_main__', 14284)
('Run', 14284)
('__main__', 14284)
主进程执行的时候，会有将当前模块的名称设置为__main__，而spawn出来的子进程中在初始化阶段该属性则为__parents_main__，而在执行阶段名称又会变回__main__。

Python 3下执行又会是如何呢？

Initialize 15088
__main__ 15088
Initialize 13992
__mp_main__ 13992
Run 13992
__mp_main__ 13992
可以发现除了子进程的模块名本身发生了变化以外，在子进程执行阶段的模块名也不再换回__main__。我猜测可能是不想让你尽可能的不要在子进程里面再开子进程吧，当然其实这也节省了开销，毕竟不用做Context的拷贝了。[？]

在Unix环境下输出如下 （Python 2.7）

('Initialize', 21)
('__main__', 21)
('Run', 22)
('__main__', 22)
这个就没有这么复杂了，子进程没有初始化阶段，直接跳到执行部分。模块名保持__main__不变。

当然对于Python 3.4以上的版本来说，Unix下也是可以使用spawn的，他的结果如下：

Initialize 64
__main__ 64
Initialize 66
__mp_main__ 66
Run 66
__mp_main__ 66
可以看到，结果与Windows下完全一致。

看到这或许有人要吐槽Windows了，但是其实fork也有他的不足。首先就是不安全，毕竟他就直接把所有句柄全部复制给子进程了。如果两者间的同步做的不足的话，那么就容易出问题。对于一些典型应用，如数据库，CUDA等等，都不是fork 安全的。另外，fork出来的子进程也不能将它对数据的改动直接传至父进程。也就是说虽然数据拿出来简单，可是要放回去就还是要想办法。


